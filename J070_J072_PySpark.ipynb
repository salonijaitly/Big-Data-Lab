{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "J070-J072_PySpark.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PPQExBYApD_"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBqVgpyqApEW",
        "outputId": "48c4638f-bbf8-47be-c3cd-53bc5ba9db19"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.sql(\"select 'spark' as hello\")\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|spark|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6GEHai0ApEb"
      },
      "source": [
        "pyspark.SparkContext (\n",
        "   master = None,\n",
        "   appName = None, \n",
        "   sparkHome = None, \n",
        "   pyFiles = None, \n",
        "   environment = None, \n",
        "   batchSize = 0, \n",
        "   serializer = PickleSerializer(), \n",
        "   conf = None, \n",
        "   gateway = None, \n",
        "   jsc = None, \n",
        "   profiler_cls = <class 'pyspark.profiler.BasicProfiler'>\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxub_ugEApEd"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext('local', 'test_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejb3Ku2SApEf",
        "outputId": "af4890f9-6a0b-44bd-b8b8-0d0768273319"
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-N55BVSI:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>test_1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=test_1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNu1rl4DApEh",
        "outputId": "8af7a988-d081-429b-edf8-ed1ff58bd4a9"
      },
      "source": [
        "x= ['Python', 'is', 'really', 'conveniant']\n",
        "print(sorted(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Python', 'conveniant', 'is', 'really']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGYJdEmJApEi",
        "outputId": "5d7827ff-c562-4fdf-9bc9-8fa6740d25b6"
      },
      "source": [
        "sorted(x, key = lambda arg : arg.lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conveniant', 'is', 'Python', 'really']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HomFpPtApEj"
      },
      "source": [
        "## filter()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKy8XQ0FApEk",
        "outputId": "2b4a11f5-929a-48f4-a43e-34f9b73ed172"
      },
      "source": [
        "list(filter(lambda arg: len(arg) < 5, x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z9kuP6xApEl",
        "outputId": "9e3e58c5-527f-4b4b-e7a3-a12cf3042e95"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    if check_length(i):\n",
        "        l1.append(i)\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P4nxMloApEn"
      },
      "source": [
        "## map()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yypp9Qn-ApEo",
        "outputId": "bcf27434-4278-4a31-e655-384e23ddbc91"
      },
      "source": [
        "print(list(map(lambda arg : check_length(arg), x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hEswew_ApEr",
        "outputId": "8bc026ac-b32d-475c-e471-682e6d9d2b3c"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    l1.append(check_length(i))\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZigqSDbApEt"
      },
      "source": [
        "## reduce()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFY7E3I6ApEu"
      },
      "source": [
        "def concat(x,y):\n",
        "    print( f'{x} + {y} = {x+y}')\n",
        "    return x + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MzAb1H8ApEv",
        "outputId": "98fbad84-dc87-4bc5-9a93-07cd50109f5b"
      },
      "source": [
        "from functools import reduce\n",
        "print(reduce(lambda i,j: concat(i,j), x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python\n",
            "is\n",
            "Pythonis\n",
            "really\n",
            "Pythonisreally\n",
            "conveniant\n",
            "Pythonisreallyconveniant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjjpnxxfApEx",
        "outputId": "32e0dc2a-cc71-497c-9d47-7960a96693c7"
      },
      "source": [
        "Python + is\n",
        "Pythonis + really\n",
        "Pythonisreally + conveniant\n",
        "Pythonisreallyconveniant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python', 'is', 'really', 'conveniant']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epsFoB4hApEy",
        "outputId": "ceeda40e-94e9-420b-8bcc-be40538efd59"
      },
      "source": [
        "print(reduce(lambda i,j: concat(i,j), range(10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 1 = 1\n",
            "1 + 2 = 3\n",
            "3 + 3 = 6\n",
            "6 + 4 = 10\n",
            "10 + 5 = 15\n",
            "15 + 6 = 21\n",
            "21 + 7 = 28\n",
            "28 + 8 = 36\n",
            "36 + 9 = 45\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o-v7VixApEz"
      },
      "source": [
        "## PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHRJElJFApE0"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pyspark\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fWejcE6ApE1",
        "outputId": "20e2d20a-525b-4cde-b86d-1f7cd137a9d7"
      },
      "source": [
        "txt = sc.textFile('file:///C:/Users/Devansh/Desktop/Aayush/Big Data/test')\n",
        "print(txt.count())\n",
        "\n",
        "python_lines = txt.filter(lambda line: 'spark' in line.lower())\n",
        "print(python_lines.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uLlqJxnApE2"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz9xe_DPApE3"
      },
      "source": [
        "## RDD Resilient Distributed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph5KF-3aApE4"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "\n",
        "words.count()\n",
        "\n",
        "words.collect()\n",
        "\n",
        "def test(x):\n",
        "    print(x)\n",
        "\n",
        "test_result = words.foreach(test)\n",
        "sc.stop()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp5hAF9tApE5"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]', 'cache check')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpynYKpaApE6",
        "outputId": "b2f07b96-28aa-4a6f-b13f-3da6ac6c560d"
      },
      "source": [
        "words.persist().is_cached"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anaP_7DApE7",
        "outputId": "4f8b8616-edaa-480d-b886-80fc30e0f047"
      },
      "source": [
        "words.cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyapWUKXApE8"
      },
      "source": [
        "## Shared Variables\n",
        "\n",
        "* Broadcast\n",
        "* Accumulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx4iL4MlApE9",
        "outputId": "17605329-d5f3-4b8c-88ab-8a0380f58db9"
      },
      "source": [
        "words_2 = sc.broadcast(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "data = words_2.value\n",
        "print(f'Stored data is {data}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stored data is ['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvqjHN1ApE_",
        "outputId": "77647d38-bb63-4dfd-e6b4-b7f5b4d51587"
      },
      "source": [
        "words_2.value[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'solaris'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03a7_LDMApFA",
        "outputId": "b70dd663-613b-4127-b0db-23dc99a2b9b2"
      },
      "source": [
        "y = sc.accumulator(100)\n",
        "def f(x):\n",
        "    global y\n",
        "    y+=x\n",
        "    \n",
        "rdd = sc.parallelize([10,20,30,40,50])\n",
        "rdd.foreach(f)\n",
        "\n",
        "final = y.value\n",
        "print(final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSdr7yguApFC"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_bqV6koApFD"
      },
      "source": [
        "## Spark mllib\n",
        "\n",
        "* classification\n",
        "* regression\n",
        "* clustering\n",
        "* linalg\n",
        "* recommendation\n",
        "* fpm"
      ]
    }
  ]
}